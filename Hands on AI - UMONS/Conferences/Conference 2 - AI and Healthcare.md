---
tags:
  - medicine
  - HandsOnAI
---
#medicine #dangersOfAI #psychiatry

Cette seconde conférence, portant sur le sujet de l'usage de l'intelligence artificielle en médecine, était animée par le psychiatre et biostatisticien Giovanni Briganti. Titulaire de la Chaire AI & Digital Medicine à l'Université de Mons et professeur en santé digitale à l'ULiège et à l'ULB, il s'est d'emblée décrit comme tout à la fois enthousiaste et très inquiet face à l'évolution de l'intelligence artificielle.
Son parcours démontre de manière évidente qu'il n'est en rien un détracteur de l'intelligence artificielle. Il tente au contraire de l'intégrer au mieux à sa pratique, et s'en est fait le porte-parole auprès de la communauté médicale belge. Mais cela ne l'empêche pas de porter un regard critique sur le sujet. Il a par ailleurs annoncé d'entrée de jeu que son objectif était de fournir de la matière à penser aux ingénieurs qui l'écoutaient, et qui potentiellement vont participer à l'avenir de l'intelligence artificielle.
Pour situer son propos, Briganti a commencé par tordre le cou à un mythe : celui qu'il serait impossible d'expliquer l'intelligence artificielle à des médecins autrement qu'en la présentant en mode "boîte noire". L'orateur s'est fermement opposé à cette idée. Selon lui, l'apprentissage de l'intelligence artificielle par les médecins est en réalité très intuitif, car l'intelligence artificielle repose, par nature, sur des concepts profondément corrélables à la biologie. Si l'on restreint le propos au Machine Learning, on ne peut en effet que lui donner raison. Les réseaux de neurones ne sont jamais que des succédanés de nos cerveaux. De même, l'apprentissage par l'erreur est également profondément inscrit dans la nature humaine.
Briganti émet l'hypothèse que le pire ennemi de l'introduction de l'intelligence artificielle en médecine n’est donc pas la capacité des médecins à s’approprier la technologie, mais bien la presse. Celle-ci véhicule en effet régulièrement l'idée que l'on pourrait voir l'intelligence artificielle, à terme, remplacer l'humain dans de nombreux domaines. Ce type de prédiction ne pouvant, évidemment, mener qu'à des levers de boucliers, surtout dans un milieu aussi animé par l’égo. Pourtant, le psychiatre est convaincu que le risque d'un remplacement est encore relativement vague. D’après lui, il y a encore de nombreux défis techniques avant d’atteindre ce stade. Mais bien qu’il relativise donc le risque, il prêche pour qu'on s'assure que le tournant ne s'opère pas. Si l'on doit retenir un enseignement de sa présentation, c'est en effet que, pour reprendre ses mots, nous ne "disposons pas de l'humanité nécessaire pour assurer ce tournant". Autrement dit, il émet un doute inquiet quant à notre capacité à faire un usage humain et raisonné de cette technologie en évolution rapide.
A plusieurs reprises au fil de sa présentation, il est revenu sur l’idée, que l’auteur de ces lignes partage par ailleurs, que les ingénieurs doivent un peu moins se poser la question du “peut-on”, et davantage celle du “devrait-on”. En effet, ce n’est pas parce qu’on dispose des moyens techniques pour relever un défi, qu’il est nécessairement pertinent de le faire effectivement. Tout défi n’est pas bon à relever. Et l’industrie est souvent trop hermétique aux questionnements éthiques.
En particulier, il émet cette idée dans le contexte de la médecine. S’il est parmi ceux qui sont convaincus du potentiel de l’intelligence artificielle pour faire progresser la médecine, il est aussi convaincu que nous devrions poser des limites claires, et surtout éviter la voie d’un remplacement des praticiens. Il revient sur le fait que l’IA ne disposant pas de corps, pas de vécu physique, elle sera toujours incapable de ressentir comme un humain, aussi performants ses modèles puissent-ils être. Il y a donc cette dimension de la corporalité qui interviendrait pour limiter naturellement les IA, et donc justifier qu’on n’accepte pas, en tant que société, qu’elles puissent à terme se substituer aux praticiens de chair et de sang.
En filigrane de ce propos principal, le praticien en a profité pour évoquer une série de questions intéressantes, sans toujours chercher à y répondre, probablement dans le but assumer de générer de la réflexion dans son auditoire. Il évoque notamment que l’une des questions qui ne sont pas assez posées dans le contexte de projets en intelligence artificielle appliqués à la médecine est celle du temps. Ce temps que les commerciaux annoncent être en mesure de faire gagner aux institutions hospitalières, comment doit-on l’investir ? A quoi servira-t-il désormais ? Si cette question n’est pas posée en amont de la concrétisation du projet en intelligence artificielle, cela ne peut, d’après Briganti, qu’exposer à des problèmes éthiques. Par exemple, ne sera-t-on pas tenté d’imposer aux praticiens davantage de consultations ? Et qu’en sera-t-il des burn-out potentiels qui en découleront ?

Question de la cross validation

Question des atouts de la Belgique

Quelques exemples où l’IA assiste déjà (surveillance, prévention, diagnostique, prédiction)

Question de la confiance pour l’adoption

Annonce que la Belgique est l’un des rares pays où l’IA est envisagée positivement par les praticiens, grâce à une sensibilisation entamée de longue date

Évoque la question intéressante de l’open source comme moyen d’assurer l’équitabilité et l’efficacité des traitements



